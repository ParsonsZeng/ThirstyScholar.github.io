{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "EPOCH = 1      \n",
    "BATCH_SIZE = 32\n",
    "TIME_STEP = 28           # input time step (image height)\n",
    "INPUT_SIZE = 28          # input size (image width)\n",
    "LR = 1e-2                \n",
    "DOWNLOAD_MNIST = False   # if download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115cef710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "*Mean substraction and normalization as data preprocessing:\n",
    "   Note that the transforms.ToTensor() scale the data into range (0, 1), so the resulting mean and std dev will be .5\n",
    "   and although MNIST images are grey scale, we still need to provide means and stddevs for 3 channels (RGB).\n",
    "\"\"\"\n",
    "data_prepro = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])\n",
    "\n",
    "\n",
    "# Load the MNIST dataset: training and test data\n",
    "train_data = dsets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,\n",
    "    transform=data_prepro,\n",
    "    download=DOWNLOAD_MNIST\n",
    ")\n",
    "\n",
    "test_data = dsets.MNIST(root='./mnist/', \n",
    "                        train=False,\n",
    "                        transform=data_prepro)\n",
    "\n",
    "# Create data loader from the datasets\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True)\n",
    "\n",
    "\"\"\"\n",
    "We create two data loader for test data:\n",
    "  1. We will examine the test accuracy as training goes along with 2,500 test data using test_loader\n",
    "  2. Examine the test accuracy on the entire test data using test_loader2\n",
    "\"\"\"\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                          batch_size=2500, \n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader2 = torch.utils.data.DataLoader(dataset=test_data, \n",
    "                                           batch_size=len(test_data))\n",
    "\n",
    "\n",
    "# Show one example\n",
    "plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "plt.title('Training example from MNIST')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network, Loss and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential (\n",
      "  (0): Linear (784 -> 128)\n",
      "  (1): ReLU ()\n",
      "  (2): Linear (128 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "fnn = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")\n",
    "print(fnn)\n",
    "\n",
    "optim_fnn = torch.optim.Adam(fnn.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=128,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(128, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \"\"\"\n",
    "        1. \"None\" indicates zero initial hidden and cell state\n",
    "        2. Discard the final hidden and cell state, don't need them for the output.\n",
    "        3. Use the output of the LSTM layer at the *last* time-step.\n",
    "        \"\"\"\n",
    "        output, (hidden, cell) = self.lstm(x, None)\n",
    "        \n",
    "        out = self.out(output[:, -1, :])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM (\n",
      "  (lstm): LSTM(28, 128, batch_first=True)\n",
      "  (out): Linear (128 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = LSTM(); print(rnn)\n",
    "optim_rnn = torch.optim.Adam(rnn.parameters(), lr=LR)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        output = self.out(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN (\n",
      "  (conv1): Sequential (\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU ()\n",
      "    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (conv2): Sequential (\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU ()\n",
      "    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (out): Linear (1568 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN(); print(cnn)\n",
    "optim_cnn = torch.optim.Adam(cnn.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Share the same loss function across 3 networks\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Mini-batch 0  \n",
      "FNN/RNN/CNN: 0.10/0.10/0.10\n",
      "\n",
      "Epoch 0 Mini-batch 50  \n",
      "FNN/RNN/CNN: 0.85/0.22/0.92\n",
      "\n",
      "Epoch 0 Mini-batch 100  \n",
      "FNN/RNN/CNN: 0.81/0.49/0.94\n",
      "\n",
      "Epoch 0 Mini-batch 150  \n",
      "FNN/RNN/CNN: 0.87/0.66/0.96\n",
      "\n",
      "Epoch 0 Mini-batch 200  \n",
      "FNN/RNN/CNN: 0.80/0.74/0.96\n",
      "\n",
      "Epoch 0 Mini-batch 250  \n",
      "FNN/RNN/CNN: 0.90/0.78/0.96\n",
      "\n",
      "Epoch 0 Mini-batch 300  \n",
      "FNN/RNN/CNN: 0.88/0.83/0.96\n",
      "\n",
      "Epoch 0 Mini-batch 350  \n",
      "FNN/RNN/CNN: 0.89/0.85/0.94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "\n",
    "    for step, (X, y) in enumerate(train_loader):\n",
    "        \n",
    "        \"\"\"\n",
    "        Here we train the 3 types of networks simultaneously\n",
    "        \"\"\"\n",
    "        \n",
    "        # FNN forward/backward pass\n",
    "        X1 = Variable(X.view(-1, 784))\n",
    "        y1 = Variable(y)\n",
    "        _y1 = fnn(X1)\n",
    "        \n",
    "        loss_fnn = loss_func(_y1, y1)\n",
    "        optim_fnn.zero_grad()                   \n",
    "        loss_fnn.backward()                         \n",
    "        optim_fnn.step()\n",
    "        \n",
    "        # RNN forward/backward pass\n",
    "        X2 = Variable(X.view(-1, 28, 28))  # squeeze the color channel, resulting shape (batch, time-step, input-size)\n",
    "        y2 = Variable(y)                       \n",
    "        _y2 = rnn(X2)\n",
    "        \n",
    "        loss_rnn = loss_func(_y2, y2)\n",
    "        optim_rnn.zero_grad()                   \n",
    "        loss_rnn.backward()                         \n",
    "        optim_rnn.step()                        \n",
    "        \n",
    "        # CNN forward/backward pass\n",
    "        X3 = Variable(X)\n",
    "        y3 = Variable(y)\n",
    "        _y3 = cnn(X3)\n",
    "        \n",
    "        loss_cnn = loss_func(_y3, y3)\n",
    "        optim_cnn.zero_grad()                   \n",
    "        loss_cnn.backward()                         \n",
    "        optim_cnn.step()\n",
    "        \n",
    "        \n",
    "        # Evaluate on 2,500 test data points to see progress\n",
    "        if step % 50 == 0:\n",
    "            \n",
    "            for X, y in test_loader:\n",
    "                \n",
    "                \"\"\"\n",
    "                Test the 3 networks simultaneously\n",
    "                \"\"\"\n",
    "                \n",
    "                # Test FNN\n",
    "                X1 = Variable(X.view(-1, 784))\n",
    "                y1 = Variable(y)\n",
    "                _y1 = fnn(X1)\n",
    "                \n",
    "                # Test RNN\n",
    "                X2 = Variable(X.view(-1, 28, 28))\n",
    "                y2 = Variable(y)                       \n",
    "                _y2 = rnn(X2)\n",
    "                \n",
    "                # Test CNN\n",
    "                X3 = Variable(X)\n",
    "                y3 = Variable(y)\n",
    "                _y3 = cnn(X3)\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                y1 = y1.data.numpy()\n",
    "                y2 = y2.data.numpy()\n",
    "                y3 = y3.data.numpy()\n",
    "                \n",
    "                # Extract predicted class\n",
    "                _y1 = torch.max(_y1, 1)[1].data.numpy().squeeze()\n",
    "                _y2 = torch.max(_y2, 1)[1].data.numpy().squeeze()\n",
    "                _y3 = torch.max(_y3, 1)[1].data.numpy().squeeze()\n",
    "                \n",
    "                # Compute accuracies\n",
    "                accu_fnn = (_y1 == y1).mean()\n",
    "                accu_rnn = (_y2 == y2).mean()\n",
    "                accu_cnn = (_y3 == y3).mean()\n",
    "                \n",
    "                break  # examine the test accuracy on 2,500 test data\n",
    "            \n",
    "            # Print epoch, mini-batch and test accuracies\n",
    "            print('Epoch {0} Mini-batch {1}  \\nFNN/RNN/CNN: {2:.2f}/{3:.2f}/{4:.2f}\\n'.\n",
    "                  format(epoch, step, accu_fnn, accu_rnn, accu_cnn))\n",
    "\n",
    "            # If the accuracy is good enough, quit training\n",
    "            if min(accu_fnn, accu_rnn, accu_cnn) > 0.85: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNN/RNN/CNN: 0.89/0.86/0.95\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_loader2:\n",
    "                \n",
    "    \"\"\"\n",
    "    Test the 3 networks simultaneously\n",
    "    \"\"\"\n",
    "\n",
    "    # Test FNN\n",
    "    X1 = Variable(X.view(-1, 784))\n",
    "    y1 = Variable(y)\n",
    "    _y1 = fnn(X1)\n",
    "\n",
    "    # Test RNN\n",
    "    X2 = Variable(X.view(-1, 28, 28))\n",
    "    y2 = Variable(y)                       \n",
    "    _y2 = rnn(X2)\n",
    "    \n",
    "    # Test CNN\n",
    "    X3 = Variable(X)\n",
    "    y3 = Variable(y)\n",
    "    _y3 = cnn(X3)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    y1 = y1.data.numpy()\n",
    "    y2 = y2.data.numpy()\n",
    "    y3 = y3.data.numpy()\n",
    "\n",
    "    # Extract predicted label\n",
    "    _y1 = torch.max(_y1, 1)[1].data.numpy().squeeze()\n",
    "    _y2 = torch.max(_y2, 1)[1].data.numpy().squeeze()\n",
    "    _y3 = torch.max(_y3, 1)[1].data.numpy().squeeze()\n",
    "\n",
    "    # Compute accuracies\n",
    "    accu_fnn = (_y1 == y1).mean()\n",
    "    accu_rnn = (_y2 == y2).mean()\n",
    "    accu_cnn = (_y3 == y3).mean()\n",
    "\n",
    "print('FNN/RNN/CNN: {0:.2f}/{1:.2f}/{2:.2f}'.format(accu_fnn, accu_rnn, accu_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
